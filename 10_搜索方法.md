---
marp: true
theme: am_blue
paginate: true
math: katex
headingDivider: [2,3,4,5]
backgroundColor: #D0E8D6DA
---

<think>让我分析一下这个项目的搜索实现和排序逻辑。从提供的文件中，我需要重点分析 `search/search.py`，因为这应该是实现搜索功能的核心文件。

首先，让我理解整个项目的大致流程：
1. 使用人脸识别技术识别视频中特定人物（张维为）的画面
2. 对这些画面进行OCR，获取字幕文本
3. 将识别结果存储为JSON文件
4. 通过搜索系统检索相关画面和字幕

现在，让我分析搜索实现的核心部分：

在 `search/search.py` 中，主要的搜索实现在 `SubtitleSearch` 类中：

1. 初始化及数据加载：
   - 使用 SentenceTransformer 模型（'BAAI/bge-large-zh-v1.5'）进行文本嵌入
   - 从 subtitle 文件夹中加载所有JSON文件，每个条目包含文本、时间戳、文件名和图像相似度

2. 索引创建：
   - 对所有字幕文本进行编码，生成嵌入向量
   - 使用 FAISS 库（Facebook AI Similarity Search）创建向量索引
   - 支持GPU加速搜索（通过USE_GPU_SEARCH参数控制）

3. 搜索实现：
   - 将查询文本转换为嵌入向量
   - 使用FAISS的L2距离（欧几里得距离）查找最相似的向量
   - 计算相似度分数（1 / (1 + 距离)）
   - 先获取大量候选结果（k * 30），然后进行过滤

4. 排序逻辑：
   - 首先根据人脸图像相似度进行过滤（self.min_image_similarity作为阈值）
   - 然后按照文本相似度降序排序（即最相关的文本排在前面）
   - 最终返回前k个结果

排序的关键代码是：
```python
# 过滤图像相似度不达标的结果
if entry.image_similarity < self.min_image_similarity:
    continue

# 收集文本相似度和图像相似度信息
text_sim = float(similarities[i])
img_sim = entry.image_similarity

results.append({
    'text_similarity': text_sim,
    'image_similarity': img_sim,
    'timestamp': entry.timestamp,
    'text': entry.text,
    'filename': entry.filename
})

# 按文本相似度排序
results.sort(key=lambda x: x['text_similarity'], reverse=True)
return results[:k]
```

因此，排序主要基于两个因素：
1. 图像相似度作为筛选条件（必须大于设定阈值）
2. 文本相似度作为排序依据（值越高排名越靠前）

这种实现方式结合了：
- 语义搜索（使用SentenceTransformer进行文本嵌入）
- 向量检索（使用FAISS高效查找相似向量）
- 多模态融合（同时考虑文本相似度和图像相似度）</think># 视频搜索系统分析

我分析了这个项目的搜索实现和排序逻辑，主要关注`search/search.py`文件。

## 搜索实现方式

该项目使用了非常先进的语义搜索技术，具体实现如下：

### 1. 核心技术栈
- **语义模型**：使用`SentenceTransformer`（模型为`BAAI/bge-large-zh-v1.5`）进行文本嵌入
- **向量检索**：使用`FAISS`（Facebook AI Similarity Search）建立高效向量索引和检索
- **支持GPU加速**：通过`USE_GPU_SEARCH`参数控制是否启用GPU搜索

### 2. 搜索流程
```
入口方法在search函数中：
```python
def search(self, query, k=None):
    if k is None:
        k = self.search_k
    
    search_k = min(k * 30, len(self.entries))
    query_embedding = self.model.encode([query], batch_size=SEARCH_BATCH_SIZE)
    distances, indices = self.index.search(query_embedding, search_k)
    
    similarities = 1 / (1 + distances[0])
    
    results = []
    for i in range(search_k):
        if i >= len(indices[0]):
            break
        entry = self.entries[indices[0][i]]
        
        # 图像相似度过滤
        if entry.image_similarity < self.min_image_similarity:
            continue
            
        text_sim = float(similarities[i])
        img_sim = entry.image_similarity
        
        results.append({
            'text_similarity': text_sim, 
            'image_similarity': img_sim,
            'timestamp': entry.timestamp,
            'text': entry.text,
            'filename': entry.filename
        })
```

### 3. 索引创建过程
1. 加载所有字幕JSON文件
2. 提取所有文本创建语义嵌入向量
3. 将嵌入向量添加到FAISS索引中

```python
def create_index(self):
    texts = [entry.text for entry in self.entries]
    self.sentence_embeddings = self.model.encode(
        texts,
        show_progress_bar=True,
        batch_size=SEARCH_BATCH_SIZE
    )
    dimension = self.sentence_embeddings.shape[1]
    if USE_GPU_SEARCH:
        res = faiss.StandardGpuResources()
        self.index = faiss.GpuIndexFlatL2(res, dimension)
    else:
        self.index = faiss.IndexFlatL2(dimension)
    self.index.add(self.sentence_embeddings)
```

## 排序逻辑

排序逻辑是这个系统的关键部分，它采用了两级筛选机制：

### 1. 初步检索
- 首先通过FAISS快速检索出潜在相关的文本（`k * 30`个结果）
- 使用L2距离（欧几里得距离）计算查询与候选项的相似度

### 2. 双重过滤机制
- **图像相似度过滤**：只保留人脸相似度超过阈值（`min_image_similarity`，默认0.6）的结果
- **文本相似度排序**：按照文本相似度从高到低排序

### 3. 最终排序代码
```python
# 按文本相似度排序
results.sort(key=lambda x: x['text_similarity'], reverse=True)
return results[:k]
```

### 4. 相似度计算方式
- 文本相似度：`1 / (1 + 距离)`，距离越小相似度越高
- 图像相似度：在人脸识别阶段已计算好，存储在JSON中

## 总结

这个搜索系统结合了：
1. **语义搜索**：使用预训练模型理解查询语义
2. **向量检索**：高效处理大量文本数据
3. **多模态融合**：同时考虑文本和图像特征
4. **性能优化**：支持GPU加速和批处理

排序采用的是"先筛选后排序"的策略：先用图像相似度筛选出确实包含目标人物的片段，再按文本相似度对结果进行精确排序，这样能确保查询结果既相关又准确。
